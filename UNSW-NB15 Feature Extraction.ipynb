{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features file found!\n"
     ]
    }
   ],
   "source": [
    "#setup imports and make ure the files we care about exist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "features_path = \"/home/jaywalker/MachineLearning/UNSW-NB15-CSV/NUSW-NB15_features.csv\"\n",
    "print(\"Features file found!\" if os.path.isfile(\"/home/jaywalker/MachineLearning/UNSW-NB15-CSV/NUSW-NB15_features.csv\") else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['no.', 'name', 'type', 'description'], dtype='object')\n",
      "                name       type\n",
      "0              srcip    nominal\n",
      "1              sport    integer\n",
      "2              dstip    nominal\n",
      "3             dsport    integer\n",
      "4              proto    nominal\n",
      "5              state    nominal\n",
      "6                dur      float\n",
      "7             sbytes    integer\n",
      "8             dbytes    integer\n",
      "9               sttl    integer\n",
      "10              dttl    integer\n",
      "11             sloss    integer\n",
      "12             dloss    integer\n",
      "13           service    nominal\n",
      "14             sload      float\n",
      "15             dload      float\n",
      "16             spkts    integer\n",
      "17             dpkts    integer\n",
      "18              swin    integer\n",
      "19              dwin    integer\n",
      "20             stcpb    integer\n",
      "21             dtcpb    integer\n",
      "22           smeansz    integer\n",
      "23           dmeansz    integer\n",
      "24       trans_depth    integer\n",
      "25       res_bdy_len    integer\n",
      "26              sjit      float\n",
      "27              djit      float\n",
      "28             stime  timestamp\n",
      "29             ltime  timestamp\n",
      "30           sintpkt      float\n",
      "31           dintpkt      float\n",
      "32            tcprtt      float\n",
      "33            synack      float\n",
      "34            ackdat      float\n",
      "35   is_sm_ips_ports     binary\n",
      "36      ct_state_ttl    integer\n",
      "37  ct_flw_http_mthd    integer\n",
      "38      is_ftp_login     binary\n",
      "39        ct_ftp_cmd    integer\n",
      "40        ct_srv_src    integer\n",
      "41        ct_srv_dst    integer\n",
      "42        ct_dst_ltm    integer\n",
      "43       ct_src_ ltm    integer\n",
      "44  ct_src_dport_ltm    integer\n",
      "45  ct_dst_sport_ltm    integer\n",
      "46    ct_dst_src_ltm    integer\n",
      "47        attack_cat    nominal\n",
      "48             label     binary\n"
     ]
    }
   ],
   "source": [
    "#quick peek at the features and cleaning up column names for easier indexing\n",
    "features_df = pd.read_csv(features_path, encoding=\"latin-1\")\n",
    "for i in range(len(features_df.columns.values)):\n",
    "    features_df.columns.values[i] = str(features_df.columns.values[i]).strip().lower()\n",
    "    \n",
    "    \n",
    "print(features_df.columns) #cleaned up column names\n",
    "\n",
    "#lower case all the types\n",
    "for i in range(len(features_df)):\n",
    "    features_df.loc[i, ['type']] = str(features_df['type'][i]).strip().lower()\n",
    "    features_df.loc[i, ['name']] = str(features_df['name'][i]).strip().lower()\n",
    "\n",
    "print(features_df[['name', 'type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes        rate  \\\n",
      "0   1  0.000011   udp       -   INT      2      0     496       0  90909.0902   \n",
      "\n",
      "   ...    ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
      "0  ...                   1               2             0           0   \n",
      "\n",
      "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
      "0                 0           1           2                0      Normal   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "\n",
      "[1 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "#quick peek at the data\n",
    "training_set_path = \"/home/jaywalker/MachineLearning/UNSW-NB15-CSV/train_test/UNSW_NB15_training-set.csv\"\n",
    "training_df = pd.read_csv(training_set_path, encoding=\"latin-1\")\n",
    "print(training_df[:1])\n",
    "#Of COURSE this file is organized differently than the features file describes.\n",
    "#Why would I expect differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur', 'sbytes',\n",
      "       'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'sload', 'dload',\n",
      "       'spkts', 'dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz',\n",
      "       'dmeansz', 'trans_depth', 'res_bdy_len', 'sjit', 'djit', 'stime',\n",
      "       'ltime', 'sintpkt', 'dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
      "       'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login',\n",
      "       'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat',\n",
      "       'label'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaywalker/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#so we'll use a file from the \"full\" dataset instead\n",
    "nb15_1_path = \"/home/jaywalker/MachineLearning/UNSW-NB15-CSV/UNSW-NB15_1.csv\"\n",
    "packet_data_df = pd.read_csv(nb15_1_path, encoding=\"latin-1\", names=features_df['name'], header=None)\n",
    "print(packet_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcip: ['175.45.176.3', '175.45.176.2', '175.45.176.0', '175.45.176.1'] type: nominal\n",
      "sport: 9983 type: integer\n",
      "dstip: 10 type: nominal\n",
      "dsport: 827 type: integer\n",
      "proto: 129 type: nominal\n",
      "state: ['INT', 'FIN', 'CON', 'REQ', 'CLO', 'ACC'] type: nominal\n",
      "dur: 8748 type: float\n",
      "sbytes: 2604 type: integer\n",
      "dbytes: 2410 type: integer\n",
      "sttl: [254, 62, 255, 0, 63] type: integer\n",
      "dttl: [0, 252, 60, 253] type: integer\n",
      "sloss: 186 type: integer\n",
      "dloss: 200 type: integer\n",
      "service: 13 type: nominal\n",
      "sload: 9501 type: float\n",
      "dload: 8654 type: float\n",
      "spkts: 225 type: integer\n",
      "dpkts: 245 type: integer\n",
      "swin: [0, 255] type: integer\n",
      "dwin: [0, 255] type: integer\n",
      "stcpb: 8584 type: integer\n",
      "dtcpb: 8552 type: integer\n",
      "smeansz: 1072 type: integer\n",
      "dmeansz: 986 type: integer\n",
      "trans_depth: [0, 1, 2, 3, 4, 8] type: integer\n",
      "res_bdy_len: 492 type: integer\n",
      "sjit: 8678 type: float\n",
      "djit: 8552 type: float\n",
      "stime: 6490 type: timestamp\n",
      "ltime: 6081 type: timestamp\n",
      "sintpkt: 8719 type: float\n",
      "dintpkt: 8581 type: float\n",
      "tcprtt: 8247 type: float\n",
      "synack: 8110 type: float\n",
      "ackdat: 7970 type: float\n",
      "is_sm_ips_ports: [0] type: binary\n",
      "ct_state_ttl: [2, 1, 3, 0, 4, 6, 5] type: integer\n",
      "ct_flw_http_mthd: [0, 1, 2] type: integer\n",
      "is_ftp_login: [0, 1] type: binary\n",
      "ct_ftp_cmd: [0, 1] type: integer\n",
      "ct_srv_src: 33 type: integer\n",
      "ct_srv_dst: 31 type: integer\n",
      "ct_dst_ltm: 16 type: integer\n",
      "ct_src_ ltm: 17 type: integer\n",
      "ct_src_dport_ltm: 16 type: integer\n",
      "ct_dst_sport_ltm: [1, 2, 3, 4, 6, 14, 8, 5] type: integer\n",
      "ct_dst_src_ltm: 16 type: integer\n",
      "attack_cat: ['Exploits', 'Reconnaissance', 'DoS', 'Generic', 'Shellcode', ' Fuzzers', 'Worms', 'Backdoors', 'Analysis'] type: nominal\n",
      "label: [1] type: binary\n"
     ]
    }
   ],
   "source": [
    "#for each feature of type \"nominal\" or \"integer\" count how many classes exist\n",
    "#print(packet_data_df['label'].unique()) #identify the different values\n",
    "\n",
    "for label, feature_type in features_df[['name', 'type']].values:\n",
    "    nunique = packet_data_df[packet_data_df['label'] == 1][label].nunique()\n",
    "    if nunique < 10:\n",
    "        value_list = packet_data_df[packet_data_df['label'] == 1][label].unique().tolist()\n",
    "        print(label + \": \" , end='')\n",
    "        print(value_list, end='')\n",
    "        print(\" type: \" + str(feature_type))\n",
    "    else:\n",
    "        print(label + \": \" + str(nunique) + \" type: \" + str(feature_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_try_kind_sort\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   2456\u001b[0m                 \u001b[0;31m# if kind==mergesort, it can fail for object dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2457\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2458\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-9c9663b9ebb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#what is the maximum port value?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mattack_sports\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpacket_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpacket_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msorted_ports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_sports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   2469\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m         \u001b[0margsorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_kind_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgood\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_try_kind_sort\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   2459\u001b[0m                 \u001b[0;31m# stable sort not available for object dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m                 \u001b[0;31m# uses the argsort default quicksort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2461\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2463\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "#what is the maximum port value?\n",
    "attack_sports =  packet_data_df[packet_data_df['label'] == 1]['sport']\n",
    "sorted_ports = attack_sports.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#How can we encode these various features, many of which are discrete integers?\n",
    "#One-hot or Binary encoding seems logical, using Binary coding to keep things compact.\n",
    "\n",
    "#Returns a list where each element are a 1 or 0, determining the binary encoding of value with\n",
    "#at least bits number of bits. If the value cannot be encoding with the requested number of bits,\n",
    "#None will be returned.\n",
    "def binary_encode(value, bits):\n",
    "    encoding = []\n",
    "    while value != 0:\n",
    "        encoding.append(value % 2)\n",
    "        value //= 2\n",
    "        \n",
    "    if bits < len(encoding):\n",
    "        return None #couldn't represent with requested number of bits\n",
    "    \n",
    "    while len(encoding) < bits:\n",
    "        encoding.append(0)\n",
    "    \n",
    "    encoding.reverse()\n",
    "    return encoding\n",
    "        \n",
    "print(binary_encode(7, 4)) #returns [0,1,1,1]\n",
    "print(binary_encode(255, 2)) #returns None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#try converting an ip into a bit array\n",
    "ip_as_bits = []\n",
    "for byte in packet_data_df['srcip'][0].split('.'):\n",
    "    ip_as_bits += binary_encode(int(byte), 8)\n",
    "    \n",
    "print(ip_as_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421927414\n",
      "[0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#lets see what some of the other relevant fields look like\n",
    "timestamp = packet_data_df['stime'][0]\n",
    "print(timestamp)\n",
    "nbits = 36\n",
    "print(binary_encode(timestamp, nbits))\n",
    "#can all the timestamps be represented with fewer bits?\n",
    "for k in packet_data_df['stime']:\n",
    "    if binary_encode(k, nbits) is None:\n",
    "        print(\"Couldn't map all the timestamps!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                name       type\n",
      "0              srcip    nominal\n",
      "1              sport    integer\n",
      "2              dstip    nominal\n",
      "3             dsport    integer\n",
      "4              proto    nominal\n",
      "5              state    nominal\n",
      "6                dur      float\n",
      "7             sbytes    integer\n",
      "8             dbytes    integer\n",
      "9               sttl    integer\n",
      "10              dttl    integer\n",
      "11             sloss    integer\n",
      "12             dloss    integer\n",
      "13           service    nominal\n",
      "14             sload      float\n",
      "15             dload      float\n",
      "16             spkts    integer\n",
      "17             dpkts    integer\n",
      "18              swin    integer\n",
      "19              dwin    integer\n",
      "20             stcpb    integer\n",
      "21             dtcpb    integer\n",
      "22           smeansz    integer\n",
      "23           dmeansz    integer\n",
      "24       trans_depth    integer\n",
      "25       res_bdy_len    integer\n",
      "26              sjit      float\n",
      "27              djit      float\n",
      "28             stime  timestamp\n",
      "29             ltime  timestamp\n",
      "30           sintpkt      float\n",
      "31           dintpkt      float\n",
      "32            tcprtt      float\n",
      "33            synack      float\n",
      "34            ackdat      float\n",
      "35   is_sm_ips_ports     binary\n",
      "36      ct_state_ttl    integer\n",
      "37  ct_flw_http_mthd    integer\n",
      "38      is_ftp_login     binary\n"
     ]
    }
   ],
   "source": [
    "#what features do I care about?\n",
    "#all the non-aggregate features that are some combination of the other features\n",
    "#either directly in an example or temporal combinations, since these should ostensibly\n",
    "#be discovered by the GAN\n",
    "features_to_use = features_df[:39]\n",
    "print(features_to_use[['name', 'type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature encoding\n",
    "-------------------------\n",
    "\n",
    "I will encode the integer based features using a binary representation, using the minimum number of bits to represent the max value plus one bit. Float based parameters will be scaled in a typical manner.\n",
    "\n",
    "IP addresses in particular are a special case, since each field is represending a collection of 4 bytes. These addresses will be represented as 32 bits, since this is the native representation and seems appropriate for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1.])\n",
      "torch.Size([96])\n",
      "torch.Size([5, 1, 96])\n",
      "tensor([[[0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "          0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "          0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "          0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "          0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "          0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "          1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "          0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "def get_minimum_bits(value):\n",
    "    min_bits = 1\n",
    "    while binary_encode(value, min_bits) is None:\n",
    "        min_bits += 1\n",
    "        \n",
    "    return min_bits\n",
    "\n",
    "def build_input_feature_tensor(packet_data_dict):\n",
    "    input_features = []\n",
    "    \n",
    "    srcip_segments = str(packet_data_dict['srcip']).split('.')\n",
    "    srcip_bits = []\n",
    "    for segment in srcip_segments:\n",
    "        for k in binary_encode(int(segment), 8):\n",
    "            srcip_bits.append(k)\n",
    "    \n",
    "    dstip_segments = str(packet_data_dict['dstip']).split('.')\n",
    "    dstip_bits = []\n",
    "    for segment in dstip_segments:\n",
    "        for k in binary_encode(int(segment), 8):\n",
    "            dstip_bits.append(k)\n",
    "            \n",
    "    sport = binary_encode(int(packet_data_dict['sport']), 16)#get_minimum_bits(int(packet_data_dict['sport'])) + 1)\n",
    "    dport = binary_encode(int(packet_data_dict['dsport']), 16)#get_minimum_bits(int(packet_data_dict['dsport'])) + 1)\n",
    "    \n",
    "    #TODO need to encode the rest of the features buuuuuttttt that can come later.\n",
    "    \n",
    "    input_features += srcip_bits + dstip_bits + sport + dport\n",
    "    \n",
    "    return torch.tensor(input_features, dtype=torch.float32)\n",
    "        \n",
    "X = build_input_feature_tensor(packet_data_df.loc[0,:].to_dict())\n",
    "\n",
    "#just playing with tensors here to figure out what I'm doing!\n",
    "print(X)\n",
    "print(X.shape)\n",
    "X_seq = torch.tensor(()).new_zeros([5,1,X.shape[0]])\n",
    "print(X_seq.shape)\n",
    "\n",
    "#wow, I did not expect this to work!\n",
    "X_seq[:,0,:] = X\n",
    "#print(X_seq)\n",
    "\n",
    "def build_input_sequence_tensor(packet_data_df, sequence_length):\n",
    "    example_feature_vector = build_input_feature_tensor(packet_data_df.loc[0,:].to_dict())\n",
    "    seq_out = torch.tensor(()).new_zeros([sequence_length, 1, example_feature_vector.shape[0]])\n",
    "    \n",
    "    for i in range(0, sequence_length):\n",
    "        #print(seq_out.shape)\n",
    "        seq_out[i,0,:] = build_input_feature_tensor(packet_data_df.loc[i,:].to_dict())\n",
    "        \n",
    "    return seq_out\n",
    "\n",
    "X_seq = build_input_sequence_tensor(packet_data_df, 5)\n",
    "print(X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I shouldn't actually do the training in this notebook, this is mostly a test to see if I've prepared\n",
    "#the features correctly for input to some RNN network.\n",
    "\n",
    "#MODELS: Define Generator model and Discriminator model\n",
    "#For the time being, this will be a one-layer RNN that is the same width as the input feature tensor\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, h0 = self.gru(x)\n",
    "        return self.f(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.map = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.gru(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3890, 0.5387, 0.4934, 0.5404, 0.5144, 0.5162, 0.5075, 0.4695,\n",
      "          0.4950, 0.5109, 0.5071, 0.4768, 0.5249, 0.5160, 0.4756, 0.4492,\n",
      "          0.4785, 0.4749, 0.5394, 0.4704, 0.5635, 0.5255, 0.5268, 0.5061,\n",
      "          0.5601, 0.5043, 0.4670, 0.4438, 0.5158, 0.4365, 0.5447, 0.4860,\n",
      "          0.5568, 0.5382, 0.4982, 0.4613, 0.5007, 0.5568, 0.4177, 0.5360,\n",
      "          0.4976, 0.5547, 0.5424, 0.4071, 0.5155, 0.5674, 0.4394, 0.5049,\n",
      "          0.4310, 0.5329, 0.5635, 0.4824, 0.4852, 0.4906, 0.5533, 0.4787,\n",
      "          0.5790, 0.5477, 0.4908, 0.4568, 0.5629, 0.5702, 0.4569, 0.4063,\n",
      "          0.4697, 0.4988, 0.5078, 0.4799, 0.5559, 0.5438, 0.4282, 0.4819,\n",
      "          0.4470, 0.5448, 0.5295, 0.4777, 0.4931, 0.5364, 0.4797, 0.5622,\n",
      "          0.4672, 0.5092, 0.4035]],\n",
      "\n",
      "        [[0.3672, 0.5635, 0.4803, 0.5614, 0.4963, 0.5383, 0.5083, 0.4593,\n",
      "          0.4911, 0.5183, 0.5079, 0.4590, 0.5366, 0.5218, 0.4729, 0.4274,\n",
      "          0.4648, 0.4765, 0.5630, 0.4497, 0.5979, 0.5305, 0.5408, 0.5035,\n",
      "          0.5772, 0.5091, 0.4577, 0.4267, 0.5187, 0.3997, 0.5582, 0.4917,\n",
      "          0.5856, 0.5602, 0.5023, 0.4501, 0.5028, 0.5966, 0.3763, 0.5608,\n",
      "          0.5013, 0.5788, 0.5609, 0.3718, 0.5218, 0.5964, 0.4041, 0.5002,\n",
      "          0.4018, 0.5531, 0.5858, 0.4658, 0.4727, 0.4883, 0.5843, 0.4621,\n",
      "          0.6105, 0.5754, 0.4759, 0.4266, 0.5922, 0.5835, 0.4353, 0.3762,\n",
      "          0.4479, 0.4987, 0.5048, 0.4698, 0.5954, 0.5738, 0.4024, 0.4669,\n",
      "          0.4322, 0.5730, 0.5370, 0.4579, 0.5031, 0.5585, 0.4648, 0.5881,\n",
      "          0.4477, 0.5371, 0.3636]],\n",
      "\n",
      "        [[0.3631, 0.5795, 0.4691, 0.5740, 0.4816, 0.5570, 0.5078, 0.4558,\n",
      "          0.4903, 0.5232, 0.5083, 0.4476, 0.5427, 0.5235, 0.4755, 0.4163,\n",
      "          0.4560, 0.4840, 0.5768, 0.4378, 0.6148, 0.5307, 0.5497, 0.5025,\n",
      "          0.5817, 0.5123, 0.4561, 0.4223, 0.5190, 0.3796, 0.5628, 0.4992,\n",
      "          0.6005, 0.5719, 0.5060, 0.4492, 0.5046, 0.6225, 0.3539, 0.5760,\n",
      "          0.5093, 0.5903, 0.5702, 0.3594, 0.5242, 0.6083, 0.3836, 0.4934,\n",
      "          0.3894, 0.5646, 0.5941, 0.4551, 0.4643, 0.4890, 0.6028, 0.4511,\n",
      "          0.6244, 0.5910, 0.4626, 0.4078, 0.6046, 0.5838, 0.4248, 0.3667,\n",
      "          0.4337, 0.4994, 0.4998, 0.4654, 0.6208, 0.5945, 0.3933, 0.4582,\n",
      "          0.4279, 0.5897, 0.5359, 0.4428, 0.5132, 0.5731, 0.4546, 0.5990,\n",
      "          0.4375, 0.5568, 0.3445]],\n",
      "\n",
      "        [[0.3625, 0.5900, 0.4614, 0.5817, 0.4730, 0.5706, 0.5072, 0.4547,\n",
      "          0.4915, 0.5265, 0.5087, 0.4405, 0.5460, 0.5235, 0.4782, 0.4100,\n",
      "          0.4504, 0.4903, 0.5851, 0.4315, 0.6227, 0.5301, 0.5557, 0.5028,\n",
      "          0.5827, 0.5140, 0.4566, 0.4219, 0.5191, 0.3691, 0.5653, 0.5050,\n",
      "          0.6082, 0.5777, 0.5084, 0.4512, 0.5056, 0.6392, 0.3412, 0.5847,\n",
      "          0.5170, 0.5958, 0.5754, 0.3556, 0.5245, 0.6129, 0.3716, 0.4873,\n",
      "          0.3843, 0.5709, 0.5977, 0.4490, 0.4587, 0.4907, 0.6140, 0.4443,\n",
      "          0.6310, 0.5997, 0.4524, 0.3964, 0.6096, 0.5815, 0.4195, 0.3634,\n",
      "          0.4245, 0.5006, 0.4956, 0.4642, 0.6368, 0.6090, 0.3901, 0.4544,\n",
      "          0.4266, 0.5996, 0.5318, 0.4317, 0.5201, 0.5828, 0.4474, 0.6036,\n",
      "          0.4326, 0.5681, 0.3346]],\n",
      "\n",
      "        [[0.3625, 0.5971, 0.4564, 0.5866, 0.4683, 0.5797, 0.5067, 0.4546,\n",
      "          0.4932, 0.5289, 0.5093, 0.4360, 0.5478, 0.5229, 0.4800, 0.4062,\n",
      "          0.4468, 0.4946, 0.5902, 0.4286, 0.6265, 0.5297, 0.5599, 0.5034,\n",
      "          0.5827, 0.5147, 0.4574, 0.4226, 0.5195, 0.3637, 0.5671, 0.5090,\n",
      "          0.6121, 0.5803, 0.5098, 0.4536, 0.5059, 0.6498, 0.3337, 0.5894,\n",
      "          0.5225, 0.5986, 0.5785, 0.3547, 0.5240, 0.6145, 0.3645, 0.4825,\n",
      "          0.3824, 0.5745, 0.5994, 0.4456, 0.4549, 0.4922, 0.6209, 0.4403,\n",
      "          0.6342, 0.6047, 0.4452, 0.3894, 0.6117, 0.5793, 0.4165, 0.3622,\n",
      "          0.4186, 0.5020, 0.4924, 0.4644, 0.6468, 0.6190, 0.3887, 0.4532,\n",
      "          0.4261, 0.6054, 0.5272, 0.4238, 0.5243, 0.5891, 0.4423, 0.6054,\n",
      "          0.4303, 0.5746, 0.3291]]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaywalker/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "G = Generator(X_seq.shape[2], X_seq.shape[2], X_seq.shape[2], torch.sigmoid)\n",
    "D = Discriminator(X_seq.shape[2], X_seq.shape[2], X_seq.shape[2], torch.sigmoid)\n",
    "\n",
    "print(G(torch.tensor(X_seq).detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
