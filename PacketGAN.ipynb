{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train' from '/home/jaywalker/MachineLearning/PacketGAN/train.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup imports and make ure the files we care about exist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "#custom modules\n",
    "import feature_extraction\n",
    "import unsw_nb15_dataset\n",
    "import generator_discriminator\n",
    "import train\n",
    "\n",
    "from importlib import reload #allow us to reload custom modules any time we like with modifications\n",
    "reload(feature_extraction)\n",
    "reload(unsw_nb15_dataset)\n",
    "reload(generator_discriminator)\n",
    "reload(train)\n",
    "\n",
    "#fe.test_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set some hyperparameters\n",
    "sequence_length=25\n",
    "batch_size=1\n",
    "\n",
    "#first, load the dataset\n",
    "data_set = unsw_nb15_dataset.UNSW_NB15(['/home/jaywalker/MachineLearning/PacketGAN/UNSW-NB15_1_clean.csv'],\n",
    "                                       sequence_length=sequence_length, \n",
    "                                       transform=feature_extraction.build_feature_sequence_tensor)\n",
    "\n",
    "#pick out the attack examples\n",
    "data_set.use_only_category('DoS'); #in this case just look at DoS attack samples\n",
    "\n",
    "#convert attack examples into time windows for training\n",
    "#DONE by the UNSW_NB15 class at load-time\n",
    "\n",
    "#convert each window into appropriate feature tensor\n",
    "#DONE by the transform function passed to the UNSW_NB15 class at load-time\n",
    "\n",
    "#train GAN to replace masked packets\n",
    "#by iterating over the dataset for some # of epochs\n",
    "#TODO make a python file to contain the network class definitions and training funciton\n",
    "\n",
    "data_loader = DataLoader(data_set, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "data_example = None\n",
    "for count, data in enumerate(data_loader):\n",
    "    data_example = data\n",
    "    if count == 0:\n",
    "        break\n",
    "        \n",
    "G = generator_discriminator.Generator(sequence_length, data_example.shape[2], data_example.shape[2] * 2, 30, data_example.shape[2], batch_size, torch.sigmoid)\n",
    "D = generator_discriminator.Discriminator(sequence_length, data_example.shape[2], data_example.shape[2] * 2, 1, batch_size, torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started...\n",
      "Epoch:  0\n",
      "D Real Error:  0.5489287376403809\n",
      "D Fake Error:  0.7951973080635071\n",
      "G Error:  0.6931566596031189\n",
      "Remaining time: 3:59:47.709969\n"
     ]
    }
   ],
   "source": [
    "#Train the network!\n",
    "gen, g_losses, df_losses, g_stats, df_stats = train.train(G,D,data_loader,25)\n",
    "\n",
    "#plot instantaneous losses\n",
    "plt.plot(range(len(df_losses)), df_losses, 'r-', range(len(g_losses)), g_losses, 'g-')\n",
    "plt.show()\n",
    "\n",
    "#plot loss averages\n",
    "plt.plot(range(len(df_stats.get_averages())), df_stats.get_averages(), 'r-', range(len(g_stats.get_averages())), g_stats.get_averages(), 'g-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "data_example = None\n",
    "for count, data in enumerate(data_loader):\n",
    "    data_example = data\n",
    "    if count == 0:\n",
    "        break\n",
    "print(\"Real data: \", feature_extraction.decode_feature_sequence_tensor(data_set, data_example[0]), end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "#note here that \"gen\" is the trained generator returned from the training function above\n",
    "generated_data = G(data_example).detach()\n",
    "#print(\"Shape of generated data: \", generated_data.shape)\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#print(\"Generated data: \", generated_data[0])\n",
    "print(\"Fake data: \", feature_extraction.decode_feature_sequence_tensor(data_set, G(data_example).detach()[0]))\n",
    "\n",
    "#print(\"From data set:\")\n",
    "#print(feature_extraction.decode_feature_sequence_tensor(data_set, data_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
