{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'networks' from '/home/jaywalker/MachineLearning/PacketGAN/networks.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup imports and make ure the files we care about exist\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "#custom modules\n",
    "import feature_extraction\n",
    "import unsw_nb15_dataset\n",
    "import generator_discriminator\n",
    "import networks\n",
    "\n",
    "from importlib import reload #allow us to reload custom modules any time we like with modifications\n",
    "reload(feature_extraction)\n",
    "reload(unsw_nb15_dataset)\n",
    "reload(generator_discriminator)\n",
    "reload(networks)\n",
    "\n",
    "#fe.test_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaywalker/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network input data shape:  torch.Size([1, 25, 275])\n"
     ]
    }
   ],
   "source": [
    "#set up the dataset(s)\n",
    "\n",
    "#set some hyperparameters\n",
    "sequence_length=25\n",
    "batch_size=1\n",
    "\n",
    "#first, load the dataset\n",
    "data_set = unsw_nb15_dataset.UNSW_NB15('/home/jaywalker/MachineLearning/PacketGAN/UNSW_NB15_full_clean.csv',\n",
    "                                       sequence_length=sequence_length, \n",
    "                                       transform=feature_extraction.build_feature_sequence_tensor)\n",
    "\n",
    "#pick out the attack examples\n",
    "data_set.use_only_category('DoS'); #in this case just look at DoS attack samples \n",
    "\n",
    "train_set_length = round(len(data_set) * 0.1)\n",
    "test_set_length = train_set_length\n",
    "excluded_set_length = len(data_set) - train_set_length - test_set_length\n",
    "train_set, test_set, excluded_set = random_split(data_set, [train_set_length, test_set_length, excluded_set_length])\n",
    "\n",
    "data_loader = DataLoader(train_set, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=2)\n",
    "\n",
    "data_example = None\n",
    "for count, data in enumerate(data_loader):\n",
    "    data_example = data\n",
    "    if count == 0:\n",
    "        break\n",
    "        \n",
    "print(\"Network input data shape: \", data_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features:  275\n",
      "Latent dimensions:  25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train a KMeans classifier for cluster evaluation\n",
    "import evaluation\n",
    "reload(evaluation)\n",
    "\n",
    "num_features = data_set[0].shape[1]\n",
    "print(\"Number of input features: \", num_features)\n",
    "latent_dimensions = 25\n",
    "print(\"Latent dimensions: \", latent_dimensions)\n",
    "\n",
    "#TODO FIXME write a \"batchify\" function so that ALL networks receive (and process) examples\n",
    "#with a batch dimension (don't want some with/some without)\n",
    "\n",
    "latent_space_mapper = networks.GRUMapping(num_features, latent_dimensions)\n",
    "\n",
    "#convert the train_set and test_set to a lower dimensional space for clustering\n",
    "train_set_latent = []\n",
    "for example in train_set:\n",
    "    example = feature_extraction.batchify([example])\n",
    "    train_set_latent.append(latent_space_mapper(example).detach().numpy())\n",
    "\n",
    "test_set_latent = []\n",
    "for example in test_set:\n",
    "    example = feature_extraction.batchify([example])\n",
    "    test_set_latent.append(latent_space_mapper(example).detach().numpy())\n",
    "\n",
    "kmeans = evaluation.KMeansTorch(n_clusters=10)\n",
    "kmeans.fit(train_set_latent)\n",
    "\n",
    "#are the train set and test set from the same distribution?\n",
    "train_counts, test_counts = evaluation.clusterAndCompare(kmeans, train_set_latent, test_set_latent, retrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the networks\n",
    "        \n",
    "G = generator_discriminator.Generator(sequence_length, data_example.shape[2], data_example.shape[2] * 2, 30, data_example.shape[2], batch_size, torch.sigmoid)\n",
    "D = generator_discriminator.Discriminator(sequence_length, data_example.shape[2], data_example.shape[2] * 2, 1, batch_size, torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started...\n"
     ]
    }
   ],
   "source": [
    "#train GAN to replace masked packets\n",
    "#by iterating over the dataset for some # of epochs\n",
    "\n",
    "import train\n",
    "reload(train)\n",
    "reload(networks)\n",
    "\n",
    "#Train the network!\n",
    "num_epochs = 3\n",
    "G, D, g_losses, df_losses, g_stats, df_stats = train.train_gan(G,D,data_loader,num_epochs)\n",
    "\n",
    "#plot instantaneous losses\n",
    "plt.plot(range(len(df_losses)), df_losses, 'r-', range(len(g_losses)), g_losses, 'g-')\n",
    "plt.show()\n",
    "\n",
    "#plot loss averages\n",
    "plt.plot(range(len(df_stats.get_averages())), df_stats.get_averages(), 'r-', range(len(g_stats.get_averages())), g_stats.get_averages(), 'g-')\n",
    "plt.show()\n",
    "\n",
    "#cluster and compare. Are the fake examples even remotely matching the original distribution?\n",
    "#first generate a set of masked sequences\n",
    "masked_gan_latent_test_set = []\n",
    "for example in test_set:\n",
    "    example = feature_extraction.batchify([example])\n",
    "    generated_example = G(example).detach()\n",
    "    #print(generated_example.shape)\n",
    "    #masked_example = train.get_interleaved_sequence_by_mask(in_example, generated_example, train.get_mask_vector(sequence_length, 0.2))\n",
    "    masked_example = generated_example\n",
    "    masked_gan_latent_test_set.append(latent_space_mapper(masked_example).detach().numpy())\n",
    "\n",
    "#then compare the native GAN output\n",
    "train_counts, test_counts = evaluation.clusterAndCompare(kmeans, train_set_latent, masked_gan_latent_test_set, retrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a test of the wasserstein critic/approximate wasserstein distance\n",
    "import torch.utils.data\n",
    "import evaluation\n",
    "reload(evaluation)\n",
    "\n",
    "for k in range(0, 3):\n",
    "    second_excluded_set_length = len(excluded_set) - 100 - 100 - 200\n",
    "    real_train_set, real_test_set, generator_input, second_excluded_set = random_split(excluded_set, [100, 100, 200, second_excluded_set_length]) #I'm assuming it's got at least 200 examples to spare\n",
    "    real_train_list = []\n",
    "    real_test_list = []\n",
    "    #assuming real_train_set and real_test_set are equal length\n",
    "    for i in range(0, len(real_train_set)):\n",
    "        real_train_list.append(feature_extraction.batchify([real_train_set[i]]))\n",
    "        real_test_list.append(feature_extraction.batchify([real_test_set[i]]))\n",
    "\n",
    "    fake_train_set = []\n",
    "    fake_test_set = []\n",
    "    for i in range(0, 100):\n",
    "        #for this example I'll just use the raw generator output. We can mask later.\n",
    "        #this way it's consistent with the histogram above.\n",
    "        with torch.no_grad():\n",
    "            fake_train_set.append(G(feature_extraction.batchify([generator_input[i]])))\n",
    "            fake_test_set.append(G(feature_extraction.batchify([generator_input[i+100]])))\n",
    "\n",
    "    w_hat, accuracy = evaluation.wasserstein_critic(real_train_list, real_test_list, fake_train_set, fake_test_set)\n",
    "    print(\"Wasserstein Distance: \", w_hat)\n",
    "    print(\"Classification Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_dict_compare(dict1, dict2):\n",
    "    for k in dict1:\n",
    "        if k not in dict2:\n",
    "            return None\n",
    "        \n",
    "    for k in dict1:\n",
    "        print(dict1[k], \"\\t\\t\", dict2[k])\n",
    "\n",
    "def dict_list_compare(dict_list1, dict_list2):\n",
    "    for l in range(0, len(dict_list1)):\n",
    "        print_dict_compare(dict_list1[l], dict_list2[l])\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "            \n",
    "import random\n",
    "data_example = None\n",
    "for count, data in enumerate(data_loader):\n",
    "    data_example = data\n",
    "    if count == 0:\n",
    "        break\n",
    "        \n",
    "print(\"Real data\\tFake data\")\n",
    "real_data = feature_extraction.decode_feature_sequence_tensor(data_set, data_example[0])\n",
    "\n",
    "#note here that \"gen\" is the trained generator returned from the training function above\n",
    "generated_data = G(data_example).detach()\n",
    "fake_data = feature_extraction.decode_feature_sequence_tensor(data_set, generated_data[0])\n",
    "\n",
    "dict_list_compare(real_data, fake_data)\n",
    "\n",
    "#print(\"From data set:\")\n",
    "#print(feature_extraction.decode_feature_sequence_tensor(data_set, data_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
